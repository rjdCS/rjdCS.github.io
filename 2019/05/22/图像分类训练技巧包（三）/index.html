<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="图像分类训练技巧包（三）"><meta name="keywords" content=""><meta name="author" content="JunDa Ren (Richard Ren)"><meta name="copyright" content="JunDa Ren (Richard Ren)"><title>图像分类训练技巧包（三） | RJD's Blog</title><link rel="shortcut icon" href="/r-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.6.0"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#training-refinements-训练改进"><span class="toc-number">1.</span> <span class="toc-text"> Training Refinements 训练改进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cosine-learning-rate-decay"><span class="toc-number">1.1.</span> <span class="toc-text"> Cosine Learning Rate Decay</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#label-smoothing"><span class="toc-number">1.2.</span> <span class="toc-text"> Label Smoothing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#knowledge-distillation"><span class="toc-number">1.3.</span> <span class="toc-text"> Knowledge Distillation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mixup-training"><span class="toc-number">1.4.</span> <span class="toc-text"> Mixup  Training</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#result"><span class="toc-number">1.5.</span> <span class="toc-text"> Result</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transfer-learning-迁移学习"><span class="toc-number">2.</span> <span class="toc-text"> Transfer Learning 迁移学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#object-detection-目标检测"><span class="toc-number">2.1.</span> <span class="toc-text"> Object Detection 目标检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#semantic-segmentation-语义分割"><span class="toc-number">2.2.</span> <span class="toc-text"> Semantic Segmentation 语义分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-number">3.</span> <span class="toc-text"> Reference</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars2.githubusercontent.com/u/8386277?s=460&amp;v=4"></div><div class="author-info__name text-center">JunDa Ren (Richard Ren)</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">24</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">24</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">15</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(http://ww1.sinaimg.cn/large/73c0c3d4ly1g38ret326hj20uu0ejdhs.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">RJD's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">图像分类训练技巧包（三）</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-05-22</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/深度学习需要深度学习/">深度学习需要深度学习</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">3,205</span><span class="post-meta__separator">|</span><span>阅读时长: 10 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><strong>论文名：</strong> <em><strong>Bag of Tricks for Image Classification with Convolution Neural Networks</strong></em><br>
<strong>论文地址：</strong> <em><a href="http://arxiv.org/pdf/1812.01187v2.pdf" target="_blank" rel="noopener">http://arxiv.org/pdf/1812.01187v2.pdf</a></em></p>
<p>这篇文章是亚马逊李沐团队的一篇技巧(tricks)文章，被CVPR2019收录了。虽然题目是讲的Image Classification，但是作者也说了，在目标检测，实例分类等问题上也是有一定的作用的。在此做下笔记，有理解不对的地方还请大佬们勿喷。</p>
<p>这一篇文章介绍论文的最后一部分，主要讲如何通过<strong>训练过程中的一些策略</strong>来进一步提升模型的准确率以及所有的技巧在目标检测与实例分割上的效果。还没看过前两篇文章的同学可以先看完再回来（传送门1：<a href="http://renjunda.top/2019/05/21/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%8C%85%EF%BC%88%E4%B8%80%EF%BC%89/" target="_blank" rel="noopener">图像分类训练技巧包（一）</a> 传送门2：<a href="http://renjunda.top/2019/05/21/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%E5%8C%85%EF%BC%88%E4%BA%8C%EF%BC%89/" target="_blank" rel="noopener">图像分类训练技巧包（二）</a>）。</p>
<h2 id="training-refinements-训练改进"><a class="markdownIt-Anchor" href="#training-refinements-训练改进"></a> Training Refinements 训练改进</h2>
<p>作者整理了四种训练过程中的技巧方法来提高模型的准确率。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33oihi5j21990kq0tg.jpg" alt=""></p>
<h3 id="cosine-learning-rate-decay"><a class="markdownIt-Anchor" href="#cosine-learning-rate-decay"></a> Cosine Learning Rate Decay</h3>
<p>我们都知道，在训练时，设置学习率太低，会使得训练过程太慢，但是设置学习率太高，我们又不容易得到最优解。如下图：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33of9ipj20ji09gjs8.jpg" alt=""></p>
<p>这时就需要学习率衰减，<strong>让学习率随着epoch的增加，适度的调低，从而能找到最优解</strong>。</p>
<p>常用的学习率衰减方法是常用的学习率衰减策略是步衰减（Step Decay），即每隔N个Epoch，学习率乘上一个固定系数。比如每10个epoch降低学习率为原来的10%。如图：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o2vduj20d90axdg2.jpg" alt=""></p>
<p>其中虚线线条是指数型下降曲线，蓝色线条是阶梯式下降曲线</p>
<p>这种衰减策略有一个不好的点就是，因为学习率衰减跳跃的变化较大，容易在切换学习率时引发震荡。</p>
<p>于是，德国弗雷堡大学提出使用余弦学习率衰减。（这个公式是一个简化版的公式，感兴趣的同学可以自行去看看原版。）</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33nydimj219t0oa41t.jpg" alt=""></p>
<p>其中，T为批次总数（忽略warmup阶段），t为当前批次，η为设定学习率。这样就使得学习率的衰减过程满足类余弦的过程。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o4inpj20ew0d5jsm.jpg" alt=""></p>
<p><strong>红色的线为采用“余弦衰减“策略，蓝色的为采用“步衰减”策略</strong>。可以发现，余弦衰减策略更加平滑，训练的精度提升也是逐步提升。反观步衰减策略，训练的精度是一种跳跃的形式。最后，余弦与步衰减策略都能达到差不多精度。值得注意的一点是，步衰减在60个epoch的时候就能达到最后的精度，余弦衰减需要到120个epoch才能达到。具体谁好谁不好，也说不准，还是在实验中具体问题具体选择。</p>
<h3 id="label-smoothing"><a class="markdownIt-Anchor" href="#label-smoothing"></a> Label Smoothing</h3>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33nyhmdj20va06vwfo.jpg" alt=""></p>
<p>该技巧最初由谷歌2015年提出，并应用在inception-v2的训练上。<strong>本质上是一种正则化方法，解决的问题也是为了防止过拟合</strong>。</p>
<p>我们知道多分类任务中，输入图片经过网络，在最后一层全连接层会得到输入图片对应于各个类别的置信度分数，这些分数会被softmax进行归一化处理，最终得到输入图片属于每个类别的概率。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o01kxj209y035a9x.jpg" alt=""></p>
<p>得到概率之后，在利用交叉熵函数来计算损失。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o2d3rj20ay03n0sl.jpg" alt=""></p>
<p>其中qi是真实样本分布（i表示某一类）。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33nxj1kj208k05tmx2.jpg" alt=""></p>
<p>这样就会带来一个问题。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33odbr0j20zo0didgj.jpg" alt=""></p>
<p>在训练网络的过程中，为了要得到最优的预测概率分布，就要使预测概率和标签真实概率的交叉熵最小化。在此过程中，为了达到最好的效果，预测概率分布zi将会使自身往正确标签和错误标签差值大的方向学习，这样网络会趋向去用极高的概率来输出一个分类结果，在训练样本不足的情况下，会导致网络过拟合，泛化能力差。</p>
<p><strong>并且作者认为，罪魁祸首就是qi——真实样本的分布。</strong></p>
<p>为了解决qi的问题，提出了label smoothing标签平滑的正则化方法。这种做法是想通过“软化”qi来使得在计算损失的过程中抑制过拟合。具体做法如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33oh2efj20um03naa3.jpg" alt=""></p>
<p>对label进行修改，相当于往真实分布中加入了人为噪声u(k)，为了便于计算，该噪声服从简单的均匀分布，并且由参数ϵ控制相对权重。大概效果如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33ny3ytj21570cbaa4.jpg" alt=""></p>
<p>这样一来，交叉熵公式就可以展开为：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33ofen8j21d904v74j.jpg" alt=""></p>
<p>从损失函数的角度上看，Label Smoothing相当于为损失函数增加了人为引入的先验概率 u(k) 和预测概率 q(k)之间的惩罚项，并且赋予了相对权重 ϵ。Loss函数分别以不同的权重对<strong>预测label与真实label</strong>和<strong>预测label与先验分布</strong>进行惩罚。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33ojk59j20mv0b30sx.jpg" alt=""></p>
<p>至于为什么可以做样做？</p>
<p>大概是为了枪打出头鸟吧（逃</p>
<h3 id="knowledge-distillation"><a class="markdownIt-Anchor" href="#knowledge-distillation"></a> Knowledge Distillation</h3>
<p>这也是谷歌提出的一个技巧，而且还是三位大佬所提出来的。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33oip8mj217k0abmze.jpg" alt=""></p>
<p>知识蒸馏是一种模型压缩常见方法(本质上更接近于迁移学习)，用于模型压缩指的是在teacher-student框架中，将复杂、学习能力强的网络（ teacher model ）学到的特征表示“知识”蒸馏出来，传递给参数量小、学习能力弱（ student model ）的网络。也即<strong>将集成模型的泛化能力迁移到小模型</strong>。</p>
<blockquote>
<p>知识蒸馏的总体思想，就是用一个训练好的大容量模型去指导一个小容量模型训练，从而得到更好的表现。目的是为了压缩一个大的网络结构到一个更为紧凑的网络并把知识保留下来。</p>
</blockquote>
<p>在用深度学习处理海量复杂的数据分布时，一种常见的做法是建立一个复杂的神经网络模型，如含有上百层的Resnet，这种复杂的网络往往含有多达几百万个参数。并且有着：<strong>1.在新的场景下重新训练成本过高</strong>，**2.由于模型过于庞大而难以大规模部署（deployment）**的缺点。</p>
<p>那我们能不能将大神经网络学习出来的知识作为先验，将先验知识交给小神经网络中，再之后实际应用中部署小规模的神经网络呢？</p>
<p>答案是：当然可以！</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o3f9qj20ws0prta1.jpg" alt=""></p>
<p>我们将大网络称为teacher model，小网络称为student model。</p>
<p>我们在知识蒸馏的过程中，将softmax进行了一下修改：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o1rwej20f10bqglu.jpg" alt=""></p>
<p>T是一个温度参数（与蒸馏对应），是一个超参数，取20。当T=1时，就是一般的softmax函数。</p>
<p><strong>数据之间是有相似性的</strong><br>
在一个大规模网络中，预测的种类往往是上千种，正确种类的概率值能够达到0.9，错误类的概率值可能分布在10<sup>-8~10</sup>-3这个区间中。虽然每个错误类别的的概率值都很小，但是10<sup>-3还是比10</sup>-8高了五个数量级。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o49r8j20hi0bs746.jpg" alt=""></p>
<p>比如：一只狗，在猫这个类别下的概率值可能是0.001，而在汽车这个类别下的概率值可能就只有0.0000001不到，这能够反映狗和猫比狗和汽车更为相似。但是一都是在大规模网络中才会有的关系，小规模网络就没有。这就是大规模神经网络能够得到的更为丰富的数据结构间的相似信息。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o5mjvj21cm0mwwh9.jpg" alt=""></p>
<p>大规模网络在训练的时候0-1编码来训练，我们将0-1编码称为hard-target(硬目标)，最后的softmax层来产生的概率分布其实是一个比原来硬目标更软的soft-target(软目标)。这个分布是由很多（0,1）之间的数值（概率）组成的。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o7syuj20pl082dgh.jpg" alt=""></p>
<p>Hinton认为<strong>同一个样本，用在大规模神经网络上产生的软目标来训练一个小的网络时，学习起来会更快收敛。</strong></p>
<p>（但是如果soft-targe是像这样的信息<code>[0.98 0.01 0.01]</code>，就意义不大了，所以需要在softmax中增加温度参数T。）按照softmax的分布来看，随着T参数的增大，这个软目标的分布更加均匀(一般来说T=20)。</p>
<p>具体的训练过程如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33okt9nj21830n5acy.jpg" alt=""></p>
<p>首先是利用大网络通过带有T的softmax输出一个软目标，再用这个软目标当做小网络的label，利用相同的T值来训练（<code>L(soft)</code>），此时，再加上小网络自己的损失函数(<code>L(hard)</code>)构成整体损失来完成训练。最后在实际部署中，将T值恢复到1，让类别概率偏向正确类别。</p>
<p>本文对hinton的loss进行了修改。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33nxhdsj2157033q3o.jpg" alt=""></p>
<p>虽然有些不同，但原理和hinton的一致。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33okpdnj214r0g240g.jpg" alt=""></p>
<p>T是之前所提到的温度超参数。整个网络分为两个部分，一个是标准CE，完成标准的训练，另一个是蒸馏损失，对teacher model和student model的输出差异进行惩罚，辅助学习。<code>T^2</code>用来平滑整个Loss的。</p>
<h3 id="mixup-training"><a class="markdownIt-Anchor" href="#mixup-training"></a> Mixup  Training</h3>
<p>这一技巧来自MIT和Facebook。属于数据增强类。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33ohpk2j214c055abd.jpg" alt=""></p>
<p>我们常用的数据增强就是翻转、小角度旋转等操作。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33obmm8j20nc0gqady.jpg" alt=""></p>
<p>MIT和Facebook联合提出了一种混合数据增强的策略。mixup指从训练集中随机选取两个样本(xi,yi) 和(xj,yj) ，然后构造新的样本(xˆ,yˆ)。</p>
<p>定义如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o8tn4j20hn0abq3h.jpg" alt=""></p>
<p>其中，λ∈[0,1] 为随机数，且服从Beta(α,α)分布。利用两个样本数据<code>xi</code>,<code>xj</code>来生成一个样本数据<code>x~</code>，同理，利用两个label<code>yi</code>,<code>yj</code>来生成一个label<code>y~</code>，这样一来就生成了一个新的样本<code>(x~,y~)</code>。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o8y6vj210t0fg420.jpg" alt=""></p>
<p>再用这个新样本来当做训练集进行训练。</p>
<p>可以看看Pytorch源码，能更好的理解mixup。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o0ojhj20ti0ed40m.jpg" alt=""></p>
<p>作者认为<strong>这其实就是一种抑制过拟合的策略，增加了一些扰动，从而提升了模型的泛化能力。</strong></p>
<p>这种做法同样可以运用在目标检测上。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o54bpj21cb0p8agh.jpg" alt=""></p>
<h3 id="result"><a class="markdownIt-Anchor" href="#result"></a> Result</h3>
<p>作者证明为了这些改进不仅限于ResNet架构或ImageNet数据集。首先，在ImageNet数据集上训练ResNet-50-D，Inception-V3和MobileNet并进行改进。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33oa2b3j21hc0t147o.jpg" alt=""></p>
<p>其中，w/,w/o代表with/without。从表中可见，对于ResNet-50-D网络结构，使用Knowledge Distillation策略能将Top-1精度从79.15%进一步提升到79.29%，而该策略对Inception-V3和MobileNet网络结构起反作用。作者认为，原因应该是“教师网络”为ResNet-152，和ResNet-50-D具有相似的网络结构，两者的预测分布也是相似的。但是与Inception-V3和MobileNet是完全不同的。</p>
<p>随后，作者在Places 365数据集的测试结果，结果表明，采用这几个策略进行训练的结果同样也是有效的。</p>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33o16qlj21hc0c5aei.jpg" alt=""></p>
<h2 id="transfer-learning-迁移学习"><a class="markdownIt-Anchor" href="#transfer-learning-迁移学习"></a> Transfer Learning 迁移学习</h2>
<p>作者将调查到目前为止所讨论的这些改进是否可以有益于其他的视觉任务。特别是目标检测和语义分割，并通过改变基础模型来评估它们的性能。</p>
<h3 id="object-detection-目标检测"><a class="markdownIt-Anchor" href="#object-detection-目标检测"></a> Object Detection 目标检测</h3>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33nyrckj21930j1ady.jpg" alt=""></p>
<h3 id="semantic-segmentation-语义分割"><a class="markdownIt-Anchor" href="#semantic-segmentation-语义分割"></a> Semantic Segmentation 语义分割</h3>
<p><img src="https://ws1.sinaimg.cn/large/73c0c3d4ly1g3a33oh6iuj20uc0i4780.jpg" alt=""></p>
<p>图像分割选择了最具代表性的FCN网络，可见，作者调优后的模型还是具有一定的效果。值得注意的一点是采用了cosine策略的优化效果最佳，其他的如label smoothing，mixup等方法效果不是特别的明显。作者认为，语义分割是在像素级别上进行分类。虽然使用label smoothing，mixup的模型有利于软化标签，但模糊的像素级信息可能会模糊并降低整体像素级精度。</p>
<p>至此，至此这篇***<em>Bag of Tricks for Image Classification with Convolution Neural Networks</em>*** 就介绍完了，花了几个星期的时间，内容实在是太多了。好在是也学习到了很多的新东西。</p>
<p>拜拜！</p>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<p>参考的内容有点多，主要是文章的内容太多了！！！请大家多担待！</p>
<p><a href="https://blog.csdn.net/e01528/article/details/84961432#%E5%AD%A6%E4%B9%A0%E7%8E%87%E9%A2%84%E7%83%AD%EF%BC%88warmup%EF%BC%89%2B0.8%25" target="_blank" rel="noopener">训练技巧详解【论文详解含有部分代码】Bag of Tricks for Image Classification with Convolutional Neural Networks</a></p>
<p><a href="https://blog.csdn.net/sinat_33487968/article/details/84928643" target="_blank" rel="noopener">深度学习Image Classification图像分类之Bag of Tricks for Image Classification with Convolutional Neural Net</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/51870052" target="_blank" rel="noopener">Bag of Tricks for Convolutional Neural Networks</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/53324148" target="_blank" rel="noopener">Bag of Tricks for Image Classification with CNN</a></p>
<p><a href="https://wanglichun.tech/algorithm/GluoncvPaper.html" target="_blank" rel="noopener">Amazon深度学习工程师总结的分类模型炼丹技巧总结</a></p>
<p><a href="https://blog.csdn.net/qiu931110/article/details/86684241" target="_blank" rel="noopener">深度学习 | 训练网络trick——label smoothing(附代码)</a></p>
<p><a href="https://www.cnblogs.com/zyrb/p/9699168.html" target="_blank" rel="noopener">Network 优化问题——Label Smoothing</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/64970719" target="_blank" rel="noopener">Label Smoothing Regularization LSR的原理</a></p>
<p><a href="">Deep residual learning for image recognition.</a></p>
<p><a href="">Rethinking the inception architecture for computer vision</a></p>
<p><a href="">SGDR: stochastic gradient descent with restarts</a></p>
<p><a href="">Distilling the knowledge in a neural network</a></p>
<p><a href="">mixup: Beyond empirical risk minimization</a></p>
</div></article><div class="post-meta__tag-list"></div><nav id="pagination"><div class="next-post pull-right"><a href="/2019/05/21/图像分类训练技巧包（二）/"><span>图像分类训练技巧包（二）</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(http://ww1.sinaimg.cn/large/73c0c3d4ly1g38ret326hj20uu0ejdhs.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2019 By JunDa Ren (Richard Ren)</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.0"></script><script src="/js/fancybox.js?version=1.6.0"></script><script src="/js/sidebar.js?version=1.6.0"></script><script src="/js/copy.js?version=1.6.0"></script><script src="/js/fireworks.js?version=1.6.0"></script><script src="/js/transition.js?version=1.6.0"></script><script src="/js/scroll.js?version=1.6.0"></script><script src="/js/head.js?version=1.6.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>